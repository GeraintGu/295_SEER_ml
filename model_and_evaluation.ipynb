{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import heapq\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_25 = pd.DataFrame(pd.read_csv(\"data_df_25.csv\"))\n",
    "data_mean = pd.DataFrame(pd.read_csv(\"data_df_mean.csv\"))\n",
    "data_75 = pd.DataFrame(pd.read_csv(\"data_df_75.csv\"))\n",
    "\n",
    "data_X_25 = data_25[[\"SAT Critical Reading 25th percentile score\", \n",
    "                         \"SAT Math 25th percentile score\",\n",
    "                         \"SAT Writing 25th percentile score\", \n",
    "                         \"ACT Composite 25th percentile score\"]]\n",
    "data_X_mean = data_mean[[\"SAT Critical Reading mean score\", \n",
    "                         \"SAT Math mean score\",\n",
    "                         \"SAT Writing mean score\", \n",
    "                         \"ACT Composite mean score\"]]\n",
    "data_X_75 = data_75[[\"SAT Critical Reading 75th percentile score\", \n",
    "               \"SAT Math 75th percentile score\",\n",
    "               \"SAT Writing 75th percentile score\", \n",
    "               \"ACT Composite 75th percentile score\"]]\n",
    "\n",
    "data_y = data_25[\"Name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT Critical Reading 25th percentile score</th>\n",
       "      <th>SAT Math 25th percentile score</th>\n",
       "      <th>SAT Writing 25th percentile score</th>\n",
       "      <th>ACT Composite 25th percentile score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>481.016248</td>\n",
       "      <td>490.649926</td>\n",
       "      <td>472.193501</td>\n",
       "      <td>21.112260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>75.384977</td>\n",
       "      <td>80.048377</td>\n",
       "      <td>80.773477</td>\n",
       "      <td>3.913538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>310.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>430.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>470.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>520.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>720.000000</td>\n",
       "      <td>770.000000</td>\n",
       "      <td>720.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SAT Critical Reading 25th percentile score  \\\n",
       "count                                  677.000000   \n",
       "mean                                   481.016248   \n",
       "std                                     75.384977   \n",
       "min                                    310.000000   \n",
       "25%                                    430.000000   \n",
       "50%                                    470.000000   \n",
       "75%                                    520.000000   \n",
       "max                                    720.000000   \n",
       "\n",
       "       SAT Math 25th percentile score  SAT Writing 25th percentile score  \\\n",
       "count                      677.000000                         677.000000   \n",
       "mean                       490.649926                         472.193501   \n",
       "std                         80.048377                          80.773477   \n",
       "min                        280.000000                         310.000000   \n",
       "25%                        430.000000                         415.000000   \n",
       "50%                        470.000000                         455.000000   \n",
       "75%                        530.000000                         510.000000   \n",
       "max                        770.000000                         720.000000   \n",
       "\n",
       "       ACT Composite 25th percentile score  \n",
       "count                           677.000000  \n",
       "mean                             21.112260  \n",
       "std                               3.913538  \n",
       "min                              13.000000  \n",
       "25%                              18.000000  \n",
       "50%                              20.000000  \n",
       "75%                              23.000000  \n",
       "max                              33.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_25.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.181583</td>\n",
       "      <td>4.809794</td>\n",
       "      <td>4.942225</td>\n",
       "      <td>5.710769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.720260</td>\n",
       "      <td>1.994037</td>\n",
       "      <td>1.813980</td>\n",
       "      <td>1.763667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.931818</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.636364</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>4.772727</td>\n",
       "      <td>5.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.136364</td>\n",
       "      <td>5.897436</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3\n",
       "count  677.000000  677.000000  677.000000  677.000000\n",
       "mean     5.181583    4.809794    4.942225    5.710769\n",
       "std      1.720260    1.994037    1.813980    1.763667\n",
       "min      0.000000    0.000000    0.000000    0.000000\n",
       "25%      3.931818    3.333333    3.636364    4.285714\n",
       "50%      5.000000    4.615385    4.772727    5.238095\n",
       "75%      6.136364    5.897436    5.909091    6.666667\n",
       "max     10.000000   10.000000   10.000000   10.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normDF(data_X):\n",
    "    scaler = preprocessing.MinMaxScaler(feature_range=(0, 10))\n",
    "    scaler.fit(data_X)\n",
    "    X_norm = scaler.transform(data_X)\n",
    "    data_norm_25 = pd.DataFrame(X_norm)\n",
    "    return data_norm_25\n",
    "\"\"\"\n",
    "data_norm_25 = normDF(data_X_25)\n",
    "data_norm_mean = normDF(data_X_mean)\n",
    "data_norm_75 = normDF(data_X_75)\n",
    "data_norm_75.describe()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to transform features by scaling each feature to a given range, e.g. between zero and one.\n",
    "def minmaxscaler_input(df,train_X):\n",
    "    maxlist = df.max().to_list()\n",
    "    minlist = df.min().to_list()\n",
    "    input_scale = []\n",
    "    for i in range(len(train_X)):\n",
    "        input_scale.append((train_X[i] - minlist[i])/(maxlist[i] -minlist[i])*10)\n",
    "    return input_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate the similarity between input score and all school's \n",
    "\n",
    "def similarity(compare_value, train_X,threshold=1):\n",
    "    #a= np.array(compare_value)\n",
    "    #b=np.array(input_value)\n",
    "    cos_lib = 1-pairwise_distances(compare_value,train_X)/threshold\n",
    "    cos_lib = relu1(cos_lib)\n",
    "    return cos_lib\n",
    "\n",
    "def relu1(result):\n",
    "    return min(max(result[0][0],0),1)\n",
    "#\n",
    "def similarity_sort(data_X, data_y, train_X,threshold):\n",
    "    #data is the (k,4) matrix, input_valueis a (1,4) array\n",
    "    sim_score = []\n",
    "    sim_name = []\n",
    "    name = \"\"\n",
    "    b = np.array([train_X])\n",
    "    for i in range(np.shape(data_X)[0]): # for each college\n",
    "        a= np.array([data_X.values[i]])\n",
    "\n",
    "        cos_lib = similarity(a,b,threshold)\n",
    "        \n",
    "        name = data_y[i]\n",
    "        sim_score.append(cos_lib)\n",
    "        sim_name.append(name)\n",
    "    sim_list = heapq.nlargest(3, zip(sim_score, sim_name))\n",
    "    return sim_list #return similiarity score and name of top 3 schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_input(df,data_y,input_data,threshold):\n",
    "    #max_min scale the input value to fit the dataset\n",
    "    input_value = np.array(minmaxscaler_input(df,input_data))\n",
    "    #max_min scale the chosen dataset\n",
    "    df_norm = normDF(df)\n",
    "    #calculate the similaity between input and all school's data,\n",
    "    #sort and return top 3 match school\n",
    "    sim = similarity_sort(df_norm,data_y,input_value,threshold)\n",
    "    return sim\n",
    "\n",
    "def prediction(data,input_data,threshold):\n",
    "    data_X = data.drop(columns = [\"Name\"])\n",
    "    data_y = data[\"Name\"].tolist()\n",
    "    sim_result_score = []\n",
    "    sim_result_name = []\n",
    "    for i in range(3):\n",
    "        sim_result = sim_input(data_X,data_y,input_data,threshold)[i]\n",
    "        sim_result_name.append(sim_result[1]) \n",
    "        recommend = np.array(data.loc[data[\"Name\"] == sim_result_name[i]])[0]\n",
    "        sim_result_score.append(recommend[1:].tolist())\n",
    "    return sim_result_name,sim_result_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.64705882 3.21428571 3.20987654 4.14634146]]\n",
      "[[3.64705882 2.97619048 3.20987654 4.14634146]]\n",
      "[[3.64705882 3.80952381 3.7037037  4.87804878]]\n",
      "[[4.23529412 3.80952381 3.7037037  4.87804878]]\n",
      "[[9.05882353 9.64285714 9.13580247 9.51219512]]\n",
      "0.7619047619047442\n",
      "0\n",
      "0\n",
      "0\n",
      "0.8095238095237953\n",
      "0.1482463258157367\n",
      "0.026892807197670954\n",
      "0\n",
      "0.8412698412698295\n",
      "0.2902052715131139\n",
      "0.18907733933139248\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# comapre different threshold impact to similarity funciton \n",
    "\"\"\"\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "y_true = np.array([[3.64705882,3.21428571,3.20987654,4.14634146]])\n",
    "y_pred = np.array([[4.23529412,3.80952381,3.7037037 ,4.87804878]])\n",
    "\n",
    "input_data = [490.0,500.0,480.0,22.0]\n",
    "train_data1 = [490.0,490.0,480.0,22.0]\n",
    "train_data2 = [490.0,525.0,500.0,23.5]\n",
    "train_data3 = [515.0,525.0,500.0,23.5]\n",
    "train_data4 = [720.0,770.0,720.0,33.0]\n",
    "amm = minmaxscaler_input(data_X_mean,input_data)\n",
    "bmm1 = minmaxscaler_input(data_X_mean,train_data1)\n",
    "bmm2 = minmaxscaler_input(data_X_mean,train_data2)\n",
    "bmm3 = minmaxscaler_input(data_X_mean,train_data3)\n",
    "bmm4 = minmaxscaler_input(data_X_mean,train_data4)\n",
    "a = np.array([amm])\n",
    "b1 = np.array([bmm1])\n",
    "b2 = np.array([bmm2])\n",
    "b3 = np.array([bmm3])\n",
    "b4 = np.array([bmm4])\n",
    "print(a)\n",
    "print(b1)\n",
    "print(b2)\n",
    "print(b3)\n",
    "print(b4)\n",
    "print(similarity(a,b1,1))\n",
    "print(similarity(a,b2,1))\n",
    "print(similarity(a,b3,1))\n",
    "print(similarity(a,b4,1))\n",
    "print(similarity(a,b1,1.25))\n",
    "print(similarity(a,b2,1.25))\n",
    "print(similarity(a,b3,1.25))\n",
    "print(similarity(a,b4,1.25))\n",
    "print(similarity(a,b1,1.5))\n",
    "print(similarity(a,b2,1.5))\n",
    "print(similarity(a,b3,1.5))\n",
    "print(similarity(a,b4,1.5))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010412328196584735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def mse_df(df,a,b):\n",
    "    a_nm = minmaxscaler_input(df,a)\n",
    "    b_nm = minmaxscaler_input(df,b)\n",
    "\n",
    "    pred_mse = mean_squared_error(a_nm,b_nm)\n",
    "    return pred_mse\n",
    "'''\n",
    "input_data = [490.0,500.0,480.0,22.0]\n",
    "train_data1 = [490.0,490.0,480.0,22.0]\n",
    "print(mse_df(data_X_25,input_data,train_data1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(df,threshold):\n",
    "    data_X = df.drop(columns = [\"Name\"])\n",
    "    data_y = df[\"Name\"].tolist()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, \n",
    "                                                        data_y, \n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "    mse_list = []\n",
    "    for index, row  in X_test.iterrows(): \n",
    "        input_data = row.tolist()\n",
    "        pred_name,pred_score = prediction(df,input_data,threshold)\n",
    "        for i in range(len(pred_score)):\n",
    "            pred = pred_score[i]\n",
    "            pred_mse = mse_df(data_X,input_data,pred)\n",
    "            mse_list.append(pred_mse)\n",
    "    avg_mse = sum(mse_list) / len(mse_list)\n",
    "    print(avg_mse)\n",
    "    return avg_mse\n",
    "\n",
    "def find_ideal_threshold(df):\n",
    "    least_mse_score = 1\n",
    "    ideal_threshold = 0\n",
    "    for i in np.arange(1,3,0.02):\n",
    "        curr_score =evaluation(df,i)\n",
    "        if least_mse_score > curr_score:\n",
    "            least_mse_score = curr_score\n",
    "            ideal_threshold = i\n",
    "    \n",
    "    return least_mse_score,ideal_threshold\n",
    "\n",
    "def save_threshold(df1,df2,df3):\n",
    "    lms_25, ideal_threshold_25 =find_ideal_threshold(df1)\n",
    "    lms_mean,ideal_threshold_mean =find_ideal_threshold(df2)\n",
    "    lms_75, ideal_threshold_75 =find_ideal_threshold(df3)\n",
    "    ideal = []\n",
    "    ideal.append(round(ideal_threshold_25, 2))\n",
    "    ideal.append(round(ideal_threshold_mean, 2))\n",
    "    ideal.append(round(ideal_threshold_75, 2))\n",
    "    with open('threshold.txt', 'w+') as f:\n",
    "        for item in ideal:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    print(\"The least mse score to data_25 is:\",lms_25)\n",
    "    print(\"The least mse score to data_mean is:\",lms_mean)\n",
    "    print(\"The least mse score to data_75 is:\",lms_75)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_school(input_data):\n",
    "    data_25 = pd.DataFrame(pd.read_csv(\"data_df_25.csv\"))\n",
    "    data_mean = pd.DataFrame(pd.read_csv(\"data_df_mean.csv\"))\n",
    "    data_75 = pd.DataFrame(pd.read_csv(\"data_df_75.csv\"))\n",
    "    threshold = open('threshold.txt','r').readlines()\n",
    "    threshold = [float(i) for i in threshold]\n",
    "    pred1_name,pred1_score = prediction(data_25,input_data,threshold[0])\n",
    "    pred2_name,pred2_score = prediction(data_mean,input_data,threshold[1])\n",
    "    pred3_name,pred3_score = prediction(data_75,input_data,threshold[2])\n",
    "    pred_name = pred1_name + pred2_name + pred3_name\n",
    "    pred_score = pred1_score + pred2_score + pred3_score\n",
    "    return pred_name,pred_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06865552965835404\n",
      "0.04149384489436609\n",
      "0.04149384489436609\n",
      "0.04149384489436609\n",
      "0.03293070937294537\n",
      "0.03293070937294537\n",
      "0.030563493926993292\n",
      "0.030563493926993292\n",
      "0.030563493926993292\n",
      "0.030563493926993292\n",
      "0.030563493926993292\n",
      "0.030563493926993292\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.026557800418362084\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06823537065942097\n",
      "0.06383405272172399\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.060396721391178555\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.02342176295254015\n",
      "0.25603977651401755\n",
      "0.25603977651401755\n",
      "0.25603977651401755\n",
      "0.25603977651401755\n",
      "0.25603977651401755\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.25183767145011343\n",
      "0.20441327768042888\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.19452828989053347\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.07725632705834032\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "0.032627104737324455\n",
      "The least mse score to data_25 is: 0.026557800418362084\n",
      "The least mse score to data_mean is: 0.02342176295254015\n",
      "The least mse score to data_75 is: 0.032627104737324455\n"
     ]
    }
   ],
   "source": [
    "#save_threshold(data_25,data_mean,data_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mse_25= [0.06865552965835404,0.04149384489436609,0.04149384489436609,0.04149384489436609,0.03293070937294537,\n",
    "         0.03293070937294537,0.030563493926993292,0.030563493926993292,0.030563493926993292,0.030563493926993292,\n",
    "         0.030563493926993292,0.030563493926993292,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "         0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,0.026557800418362084,\n",
    "        ]\n",
    "mse_mean = [0.06823537065942097,0.06823537065942097,0.06823537065942097,0.06823537065942097,0.06823537065942097,\n",
    "            0.06823537065942097,0.06823537065942097,0.06823537065942097,0.06823537065942097,0.06383405272172399,\n",
    "            0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,\n",
    "            0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,\n",
    "            0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,\n",
    "            0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,\n",
    "            0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,\n",
    "            0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,0.060396721391178555,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,\n",
    "            0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015,0.02342176295254015\n",
    "           ]\n",
    "\n",
    "mse_75 = [0.25603977651401755,0.25603977651401755,0.25603977651401755,0.25603977651401755,0.25603977651401755,\n",
    "          0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,\n",
    "          0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,\n",
    "          0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,\n",
    "          0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,\n",
    "          0.25183767145011343,0.25183767145011343,0.25183767145011343,0.25183767145011343,0.20441327768042888,\n",
    "          0.19452828989053347,0.19452828989053347,0.19452828989053347,0.19452828989053347,0.19452828989053347,\n",
    "          0.19452828989053347,0.19452828989053347,0.19452828989053347,0.19452828989053347,0.19452828989053347,\n",
    "          0.19452828989053347,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,0.07725632705834032,\n",
    "          0.07725632705834032,0.07725632705834032,0.032627104737324455,0.032627104737324455,0.032627104737324455,\n",
    "          0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,\n",
    "          0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,\n",
    "          0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,\n",
    "          0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455,0.032627104737324455\n",
    "         ]\n",
    "\n",
    "mse_x = np.arange(1,3,0.02)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('mse')\n",
    "plt.plot(np.array(mse_x),np.array(mse_25),np.array(mse_x),np.array(mse_mean),np.array(mse_x),np.array(mse_75))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
